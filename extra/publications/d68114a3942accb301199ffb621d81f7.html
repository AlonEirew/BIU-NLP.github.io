<style>.gsc_oms_mm{font-size:24px;line-height:16px;display:inline-block;margin:-10px 0 0 4px;position:relative;top:8px;}.gsc_oms_link{white-space:nowrap;margin-right:12px;}.gsc_oms_link:last-child{margin-right:0;}#gsc_ocd_upload{max-width:500px;margin:0 auto;}.gsc_upl_title{font-size:20px;margin:0 0 4px 0;}.gsc_upl_desc{font-size:16px;padding:24px 0;}.gs_el_ph .gsc_upl_desc{padding:16px 0;}.gsc_upl_cprt{font-size:16px;color:#777;}#gsc_upl_error:empty,#gsc_upl_form{display:none;}#gsc_upl_error{padding:8px;margin-bottom:16px;}#gsc_vcd_title_wrapper{font-size:16px;margin:0 0 16px 0;}#gsc_vcd_title{font-size:20px;}.gs_el_sm #gsc_vcd_title{font-size:18px;}#gsc_vcd_title_gg{float:right;padding:0 0 8px 16px;}.gs_el_ph #gsc_vcd_title_gg{float:none;text-align:right;padding:0;margin:-4px 0 8px 0;}.gsc_vcd_title_ggt{font-size:13px;font-weight:bold;}.gsc_vcd_title_ggut{font-size:13px;color:#777;padding-bottom:8px;}.gsc_vcd_field{float:left;width:100px;text-align:right;color:#777;}.gs_el_ph .gsc_vcd_field{float:none;width:auto;text-align:left;margin-bottom:4px;font-size:16px;color:black;}.gsc_vcd_value{margin-left:116px;max-width:512px;margin-bottom:16px;}.gs_el_ph .gsc_vcd_value{margin-left:0;}.gsc_vcd_merged_snippet{margin-bottom:1em;}#gsc_vcd_graph{position:relative;height:100px;}#gsc_vcd_graph_x{position:absolute;top:57px;left:0;width:100%;height:13px;border-top:1px solid #777;}.gsc_vcd_g_t{position:absolute;top:60px;color:#777;font-size:11px;}#gsc_vcd_graph_bars{position:absolute;top:0;right:0;width:100%;height:100px;overflow-x:auto;}.gsc_vcd_g_a{position:absolute;bottom:13px;width:15px;background:#777;}.gsc_vcd_g_a:hover{background:#1a0dab;text-decoration:none;}.gsc_vcd_g_a:active{background:#d14836;}.gsc_vcd_g_al{position:absolute;bottom:15px;left:7px;color:#222;background:white;font-size:11px;min-width:11px;text-align:center;padding:1px;border:1px solid #777;border-radius:1px;visibility:hidden;opacity:0;}.gsc_vcd_g_a:hover .gsc_vcd_g_al{visibility:visible;opacity:1;}.gsc_vcd_g_a{transition:all .218s;}.gsc_vcd_g_al{transition:opacity .218s,visibility 0s .218s;}.gsc_vcd_g_a:hover,.gsc_vcd_g_a:hover .gsc_vcd_g_al{transition:all 0s;}a.gsc_vcd_lbx:link,a.gsc_vcd_lbx:visited{white-space:nowrap;display:inline-block;vertical-align:middle;font-size:11px;background-color:#e5e5e5;color:#777;padding:2px 6px;text-decoration:none;}a.gsc_vcd_lbx:hover{color:#e5e5e5;background-color:#777;}a.gsc_vcd_lbx:active{color:#d14836;}#gsc_ecd_alrt{padding:8px 16px;margin-bottom:12px;}#gsc_ecd_alrt:empty{display:none;}.gsc_ecd_field,.gsc_ecd_value{padding:6px 0;vertical-align:top;}.gsc_ecd_field{float:left;width:100px;text-align:right;color:#777;line-height:16px;padding:13px 0 6px 0;}.gs_el_ph .gsc_ecd_field,.gs_el_tc .gsc_ecd_field{float:none;width:auto;text-align:left;padding:8px 0 0 0;font-size:16px;color:black;}#gsc_ecd_citation_type{margin-bottom:12px;}.gsc_ecd_value,#gsc_ecd_citation_type{margin-left:116px;}.gs_el_ph .gsc_ecd_value,.gs_el_tc .gsc_ecd_value,.gs_el_ta #gsc_ecd_citation_type,.gs_el_ph #gsc_ecd_citation_type{margin-left:0;padding:8px 0;}.gs_el_ta #gsc_ecd_citation_type,.gs_el_ph #gsc_ecd_citation_type{text-align:center;}.gs_el_ph #gsc_ecd_citation_type{padding:0;margin-bottom:8px;}.gs_el_ph #gsc_ecd_title_value .gs_gray,.gs_el_tc #gsc_ecd_title_value .gs_gray,#gsc_ecd_reporter_value .gs_gray{display:none;}.gsc_ecd_reporter_line{margin-bottom:4px;}.gsc_ecd_merged_snippet{line-height:1.24;}.gsc_ecd_merged_radio{line-height:18px;margin:8px 0 16px 0;color:#555;}.gsc_ecd_type_journal,.gsc_ecd_type_conference,.gsc_ecd_type_chapter,.gsc_ecd_type_book,.gsc_ecd_type_thesis,.gsc_ecd_type_patent,.gsc_ecd_type_courtcase,.gsc_ecd_type_other{display:none;}.gsc_ecd_form_journal .gsc_ecd_type_journal,.gsc_ecd_form_conference .gsc_ecd_type_conference,.gsc_ecd_form_chapter .gsc_ecd_type_chapter,.gsc_ecd_form_book .gsc_ecd_type_book,.gsc_ecd_form_thesis .gsc_ecd_type_thesis,.gsc_ecd_form_patent .gsc_ecd_type_patent,.gsc_ecd_form_courtcase .gsc_ecd_type_courtcase,.gsc_ecd_form_other .gsc_ecd_type_other{display:block;}.gsc_ecd_form_journal span.gsc_ecd_type_journal,.gsc_ecd_form_conference span.gsc_ecd_type_conference,.gsc_ecd_form_chapter span.gsc_ecd_type_chapter,.gsc_ecd_form_book span.gsc_ecd_type_book,.gsc_ecd_form_thesis span.gsc_ecd_type_thesis,.gsc_ecd_form_patent span.gsc_ecd_type_patent,.gsc_ecd_form_courtcase span.gsc_ecd_type_courtcase,.gsc_ecd_form_other span.gsc_ecd_type_other{display:inline;}#gsc_ocd_view,#gsc_ocd_upload,.gsc_ocd_bdy_upload #gsc_ocd_edit,.gsc_ocd_bdy_view #gsc_ocd_edit,#gsc_ocd_error:empty{display:none;}.gsc_ocd_bdy_upload #gsc_ocd_upload,.gsc_ocd_bdy_view #gsc_ocd_view,#gsc_ocd_edit{display:block;}#gsc_ocd_error{padding:8px;margin-bottom:16px;}</style><div id="gsc_ocd_bdy" data-btns="" class="gsc_ocd_bdy_view"><div id="gsc_ocd_error" class="gs_alrt"></div><div id="gsc_ocd_view"><form method="post" action="/citations?view_op=edit_citation&amp;update_op=&amp;hl=en&amp;oe=ASCII" id="gsc_vcd_form" data-url="/citations?hl=en&amp;oe=ASCII"><input id="gsc_vcd_xsrf" type="hidden" name="xsrf" value="AMD79ooAAAAAX6pn1zJkS849JHOwVEZWS7pesTsdSHCd"><input id="gsc_vcd_cid" type="hidden" name="s" value="0rskDKgAAAAJ:yJjnfzR0HrkC"><div id="gsc_vcd_title_wrapper"><div id="gsc_vcd_title_gg"><div class="gsc_vcd_title_ggi"><a href="https://arxiv.org/pdf/1908.07898" data-clk="hl=en&amp;sa=T&amp;ei=VxapX8zQC8LPmAHXtJSIAQ&amp;scisig=AAGBfm1R1D2x6wwm_BMRm8B70Eo1Pf1djQ&amp;nossl=1"><span class='gsc_vcd_title_ggt'>[PDF]</span> from arxiv.org</a></div></div><div id="gsc_vcd_title"><a class="gsc_vcd_title_link" href="https://arxiv.org/abs/1908.07898" data-clk="hl=en&amp;sa=T&amp;ei=VxapX8zQC8LPmAHXtJSIAQ&amp;scisig=AAGBfm1q2OOeE8WyZhQrLx1aDFrb-ZbMvQ&amp;nossl=1">Are we modeling the task or the annotator? an investigation of annotator bias in natural language understanding datasets</a></div></div><div id="gsc_vcd_table"><div class="gs_scl"><div class="gsc_vcd_field">Authors</div><div class="gsc_vcd_value">Mor Geva, Yoav Goldberg, Jonathan Berant</div></div><div class="gs_scl"><div class="gsc_vcd_field">Publication date</div><div class="gsc_vcd_value">2019/8/21</div></div><div class="gs_scl"><div class="gsc_vcd_field">Journal</div><div class="gsc_vcd_value">arXiv preprint arXiv:1908.07898</div></div><div class="gs_scl"><div class="gsc_vcd_field">Description</div><div class="gsc_vcd_value" id="gsc_vcd_descr"><div class="gsh_small"><div class="gsh_csp">Crowdsourcing has been the prevalent paradigm for creating natural language understanding datasets in recent years. A common crowdsourcing practice is to recruit a small number of high-quality workers, and have them massively generate examples. Having only a few workers generate the majority of examples raises concerns about data diversity, especially when workers freely generate sentences. In this paper, we perform a series of experiments showing these concerns are evident in three recent NLP datasets. We show that model performance improves when training with annotator identifiers as features, and that models are able to recognize the most productive annotators. Moreover, we show that often models do not generalize well to examples from annotators that did not contribute to the training set. Our findings suggest that annotator bias should be monitored during dataset creation, and that test set annotators should be disjoint from training set annotators.</div></div></div></div><div class="gs_scl"><div class="gsc_vcd_field">Total citations</div><div class="gsc_vcd_value"><div style="margin-bottom:1em"><a href="https://scholar.google.co.il/scholar?oi=bibs&amp;hl=en&amp;oe=ASCII&amp;cites=6161356713428783474&amp;as_sdt=5">Cited by 45</a></div><div id="gsc_vcd_graph"><div id="gsc_vcd_graph_x"></div><div id="gsc_vcd_graph_bars"><span class="gsc_vcd_g_t" style="left:0px">2019</span><span class="gsc_vcd_g_t" style="left:33px">2020</span><a href="https://scholar.google.co.il/scholar?oi=bibs&amp;hl=en&amp;oe=ASCII&amp;cites=6161356713428783474&amp;as_sdt=5&amp;as_ylo=2019&amp;as_yhi=2019" class="gsc_vcd_g_a" style="left:5px;height:16px;top:41px;z-index:2"><span class="gsc_vcd_g_al">10</span></a><a href="https://scholar.google.co.il/scholar?oi=bibs&amp;hl=en&amp;oe=ASCII&amp;cites=6161356713428783474&amp;as_sdt=5&amp;as_ylo=2020&amp;as_yhi=2020" class="gsc_vcd_g_a" style="left:38px;height:57px;top:0px;z-index:1"><span class="gsc_vcd_g_al">35</span></a></div></div></div></div><div class="gs_scl"><div class="gsc_vcd_field">Scholar articles</div><div class="gsc_vcd_value"><div class="gsc_vcd_merged_snippet"><div><a href="http://scholar.google.co.il/scholar?oi=bibs&amp;cluster=6161356713428783474&amp;btnI=1&amp;nossl=1&amp;hl=en&amp;oe=ASCII">Are we modeling the task or the annotator? an investigation of annotator bias in natural language understanding datasets</a></div><div>M Geva, Y Goldberg, J Berant - arXiv preprint arXiv:1908.07898, 2019</div><div><a class="gsc_oms_link" href="https://scholar.google.co.il/scholar?oi=bibs&amp;hl=en&amp;oe=ASCII&amp;cites=6161356713428783474&amp;as_sdt=5">Cited by 45</a> <a class="gsc_oms_link" href="https://scholar.google.co.il/scholar?oi=bibs&amp;hl=en&amp;oe=ASCII&amp;q=related:chFkXkmJgVUJ:scholar.google.com/">Related articles</a> <a class="gsc_oms_link" href="https://scholar.google.co.il/scholar?oi=bibs&amp;hl=en&amp;oe=ASCII&amp;cluster=6161356713428783474">All 5 versions</a> </div></div></div></div></div></form></div><div id="gsc_ocd_edit"></div><div id="gsc_ocd_upload"></div></div>